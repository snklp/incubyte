{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql import functions as F"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93630cb2-e01e-462c-ac4c-fe8c2f25a679"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["  spark = SparkSession.builder.appName('Script').master('local[*]').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0b96912-1aca-407e-aea1-8fb0a16818d1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Extraction\n\ndef extract(file_path, file_type):\n    return spark.read.format(file_type).option('header', True).load(file_path) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Extraction","showTitle":true,"inputWidgets":{},"nuid":"0f21d79d-e32a-4d31-a7bd-8fea2d236bbd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Cleaning\n\ndef cleanse_USA(df_USA):\n    return df_USA.drop('ID', 'Name', 'VaccinationDate').dropna().withColumn('CountryName', lit('USA'))\n\ndef cleanse_IND(df_IND):\n    return df_IND.drop('ID', 'Name', 'DOB', 'VaccinationDate', 'Free or Paid').dropna().withColumn('CountryName', lit('IND'))\n\ndef cleanse_AUS(df_AUS):\n    return df_AUS.drop('Unique ID', 'Patient Name', 'Date of Birth', 'Date of Vaccination').dropna().withColumn('CountryName', lit('AUS')).withColumnRenamed('Vaccine Type', 'VaccinationType')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Cleaning","showTitle":true,"inputWidgets":{},"nuid":"57f0bb85-bd2d-43f1-8346-a88de76689c8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Merging\n\ndef merge_all(df_USA, df_IND, df_AUS):\n    cleansed_df_USA = cleanse_USA(df_USA)\n    cleansed_df_IND = cleanse_IND(df_IND)\n    cleansed_df_AUS = cleanse_AUS(df_AUS)\n    return cleansed_df_USA.unionByName(cleansed_df_IND).unionByName(cleansed_df_AUS)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Merging","showTitle":true,"inputWidgets":{},"nuid":"a1baffc2-b65f-4ec8-bc8e-74abc4bf4bb1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Transforming & Aggregating\n\ndef metric(df_USA, df_IND, df_AUS):\n    \n    countries_data = [\n        ('USA', 3295),\n        ('IND', 13800),\n        ('AUS', 257)]\n    coutries_columns = ['CountryName', 'TotalPopulation']\n    countries = spark.createDataFrame(countries_data, coutries_columns)\n    \n    df = merge_all(df_USA, df_IND, df_AUS)\n    \n    metric1 = df.groupby('CountryName', 'VaccinationType').agg(F.count('VaccinationType').alias('No. of vaccinations'))\n    \n    temp = df.groupby('CountryName').agg(F.count('VaccinationType').alias('count'))\n    metric2 = temp.withColumn('% Contribution', temp['count']/df.count()*100).drop('count')    \n    temp = df.groupby('CountryName').agg(F.count('VaccinationType').alias('count'))\n    temp = temp.join(countries, on='CountryName')\n    metric3 = temp.withColumn('% Vaccinated', temp['count']/temp['TotalPopulation']*100).drop('count', 'TotalPopulation')  \n    \n    return metric1, metric2, metric3"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Transforming & Aggregating","showTitle":true,"inputWidgets":{},"nuid":"9fb8b5d6-0a4c-46ad-afee-825345fe9c17"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Unit Testing\n\nimport unittest\n\nclass TestNotebook(unittest.TestCase):\n        \n    def test_cleanse_USA(self):\n        \n        test_data = [(1,'Sam','EFG',6152022),\n                     (2,'John','XYZ',1052022),\n                     (3,'Mike','ABC',12282021)]\n        \n        data = ['ID', 'Name', 'VaccinationType', 'VaccinationDate']\n        \n        test_df = spark.createDataFrame(test_data,data)\n        \n        res = cleanse_USA(test_df)\n    \n        self.assertEqual(res.count(), 3)\n        self.assertEqual(len(res.columns), 2)\n        \n    def test_cleanse_IND(self):\n        \n        test_data = [(1,'Sam','EFG','1998-12-01', '1998-12-01','F'),\n                     (2,'John','XYZ', '1998-12-01', '1998-12-01','F'),\n                     (3,'Mike','ABC', '1998-12-01', '1998-12-01','F')]\n        \n        data = ['ID', 'Name', 'DOB', 'VaccinationType', 'VaccinationDate', 'Free or Paid']\n        \n        test_df = spark.createDataFrame(test_data,data)\n        \n        res = cleanse_IND(test_df)\n    \n        self.assertEqual(res.count(), 3)\n        self.assertEqual(len(res.columns), 2)\n        self.assertListEqual(res.columns, ['VaccinationType', 'CountryName'])\n        \n    def test_cleanse_AUS(self):\n        \n        test_data = [(1,'Sam', 'EFG', 'NULL', 6152022),\n                     (2,'John', 'XYZ', '1998-12-01', 105202),\n                     (3,'Mike', 'ABC', '1998-12-03', 122821)]\n        \n        data = ['Unique ID', 'Patient Name', 'Vaccine Type', 'Date of Birth', 'Date of Vaccination']\n        \n        test_df = spark.createDataFrame(test_data,data)\n        \n        res = cleanse_AUS(test_df)\n    \n        self.assertEqual(res.count(), 3)\n        self.assertEqual(len(res.columns), 2)\n        self.assertListEqual(res.columns, ['VaccinationType', 'CountryName'])\n        \n    def test_merge_all(self):\n        \n        data = ['VaccinationType', 'CountryName']\n        \n        test_df1 = spark.createDataFrame([('EFG',6152022)], data)\n        test_df2 = spark.createDataFrame([('XYZ',1052022)], data)\n        test_df3 = spark.createDataFrame([('ABC',1228219)], data)\n        \n        res = merge_all(test_df1, test_df2, test_df3)\n    \n        self.assertEqual(res.count(), 3)\n        self.assertEqual(len(res.columns), 2)\n        self.assertListEqual(res.columns, data)\n        \n    def test_metric(self):\n        \n        test_df1 = spark.createDataFrame([('EFG','AUS'),\n                                     ('XYZ','AUS'),\n                                     ('ABC','AUS')],\n                                    ['VaccinationType', 'CountryName'])\n        test_df2 = spark.createDataFrame([('XYZ','AUS'),\n                                     ('ABC','AUS'),\n                                     ('ABC','AUS')],\n                                    ['VaccinationType', 'CountryName'])\n        test_df3 = spark.createDataFrame([('LMN','AUS'),\n                                     ('XYZ','AUS'),\n                                     ('ABC','AUS')],\n                                    ['VaccinationType', 'CountryName'])\n        \n        res1, res2, res3 = metric(test_df1, test_df2, test_df3)\n        \n        self.assertEqual(res1.count(), 8)\n        self.assertEqual(res2.count(), 3)\n        self.assertEqual(res3.count(), 3)\n        self.assertEqual(round(res2.select('% Contribution').agg(F.sum('% Contribution')).collect()[0][0]),100)\n        \n        \nunittest.main(argv=[''], verbosity=3, exit=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Unit Testing","showTitle":true,"inputWidgets":{},"nuid":"d497fb1a-281a-450c-b1d7-0a507b1a1b30"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"test_cleanse_AUS (__main__.TestNotebook) ... ok\ntest_cleanse_IND (__main__.TestNotebook) ... ok\ntest_cleanse_USA (__main__.TestNotebook) ... ok\ntest_merge_all (__main__.TestNotebook) ... ok\ntest_metric (__main__.TestNotebook) ... /usr/lib/python3.8/socket.py:740: ResourceWarning: unclosed <socket.socket fd=57, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 47130), raddr=('127.0.0.1', 41793)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\nok\n\n----------------------------------------------------------------------\nRan 5 tests in 10.990s\n\nOK\nOut[16]: <unittest.main.TestProgram at 0x7f8a3b10f2b0>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["test_cleanse_AUS (__main__.TestNotebook) ... ok\ntest_cleanse_IND (__main__.TestNotebook) ... ok\ntest_cleanse_USA (__main__.TestNotebook) ... ok\ntest_merge_all (__main__.TestNotebook) ... ok\ntest_metric (__main__.TestNotebook) ... /usr/lib/python3.8/socket.py:740: ResourceWarning: unclosed <socket.socket fd=57, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 47130), raddr=('127.0.0.1', 41793)>\n  self._sock = None\nResourceWarning: Enable tracemalloc to get the object allocation traceback\nok\n\n----------------------------------------------------------------------\nRan 5 tests in 10.990s\n\nOK\nOut[16]: <unittest.main.TestProgram at 0x7f8a3b10f2b0>"]}}],"execution_count":0},{"cell_type":"code","source":["# Config\n\nfile_path_USA = '/FileStore/tables/USA-1.csv'  #sample_file\nfile_path_IND = '/FileStore/tables/IND.csv'    #sample_file\nfile_path_AUS = '/FileStore/tables/AUS.xlsx'   #sample_file\n\ncsv = 'csv'\nexcel = 'com.crealytics.spark.excel'\n\ndf_USA = extract(file_path_USA, csv)\ndf_IND = extract(file_path_IND, csv)\ndf_AUS = extract(file_path_AUS, excel)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Config","showTitle":true,"inputWidgets":{},"nuid":"07af732b-bc05-4c05-aced-edee48e9c9fb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Metrics based on Sample File\n\nmetric1, metric2, metric3 = metric(df_USA, df_IND, df_AUS)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Metrics based on Sample File","showTitle":true,"inputWidgets":{},"nuid":"7c114997-7134-4028-83fa-e977cdc4535d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["metric1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c974dd6-e90e-431e-bc79-9a880853c6f3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------+---------------+-------------------+\n|CountryName|VaccinationType|No. of vaccinations|\n+-----------+---------------+-------------------+\n|        USA|            XYZ|                  1|\n|        USA|            EFG|                  1|\n|        USA|            ABC|                  1|\n|        IND|            ABC|                  2|\n|        IND|            XYZ|                  1|\n|        AUS|            LMN|                  1|\n|        AUS|            XYZ|                  1|\n|        AUS|            ABC|                  1|\n+-----------+---------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+---------------+-------------------+\n|CountryName|VaccinationType|No. of vaccinations|\n+-----------+---------------+-------------------+\n|        USA|            XYZ|                  1|\n|        USA|            EFG|                  1|\n|        USA|            ABC|                  1|\n|        IND|            ABC|                  2|\n|        IND|            XYZ|                  1|\n|        AUS|            LMN|                  1|\n|        AUS|            XYZ|                  1|\n|        AUS|            ABC|                  1|\n+-----------+---------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["metric2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55af4e09-6988-424d-9c2c-9263e6a54448"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------+-----------------+\n|CountryName|   % Contribution|\n+-----------+-----------------+\n|        USA|33.33333333333333|\n|        IND|33.33333333333333|\n|        AUS|33.33333333333333|\n+-----------+-----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+-----------------+\n|CountryName|   % Contribution|\n+-----------+-----------------+\n|        USA|33.33333333333333|\n|        IND|33.33333333333333|\n|        AUS|33.33333333333333|\n+-----------+-----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["metric3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd1ce995-5ba8-418e-bb28-02cbb2751651"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------+--------------------+\n|CountryName|        % Vaccinated|\n+-----------+--------------------+\n|        USA| 0.09104704097116845|\n|        IND|0.021739130434782608|\n|        AUS|  1.1673151750972763|\n+-----------+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------+--------------------+\n|CountryName|        % Vaccinated|\n+-----------+--------------------+\n|        USA| 0.09104704097116845|\n|        IND|0.021739130434782608|\n|        AUS|  1.1673151750972763|\n+-----------+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# writing the sample data\nmetric1.write.csv('metric1.csv')\nmetric2.write.csv('metric2.csv')\nmetric3.write.csv('metric3.csv')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31f3fcbb-5b72-4954-8867-3c7f8a416e97"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2022-08-03 - DBFS Example (1)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":999697145083571}},"nbformat":4,"nbformat_minor":0}
